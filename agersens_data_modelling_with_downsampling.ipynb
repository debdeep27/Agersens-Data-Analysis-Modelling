{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling of Agersens Data with Downsampling\n",
    "\n",
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "import xgboost as xg\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data from the data provided using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "agersens_df = pd.read_csv('/data/shared/debdeep_guha/agersens_data/location.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Location_1</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.706060</td>\n",
       "      <td>145.126555</td>\n",
       "      <td>6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.33</td>\n",
       "      <td>43.98</td>\n",
       "      <td>10.995</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.66</td>\n",
       "      <td>999.62</td>\n",
       "      <td>17.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Location_2</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.706120</td>\n",
       "      <td>145.126457</td>\n",
       "      <td>11</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.52</td>\n",
       "      <td>38.72</td>\n",
       "      <td>2.816</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>2.4</td>\n",
       "      <td>10.56</td>\n",
       "      <td>1000.17</td>\n",
       "      <td>22.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Location_3</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.706122</td>\n",
       "      <td>145.126435</td>\n",
       "      <td>12</td>\n",
       "      <td>0.7</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.93</td>\n",
       "      <td>35.16</td>\n",
       "      <td>2.051</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>2.1</td>\n",
       "      <td>8.79</td>\n",
       "      <td>986.20</td>\n",
       "      <td>21.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Location_4</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.706123</td>\n",
       "      <td>145.126427</td>\n",
       "      <td>13</td>\n",
       "      <td>0.7</td>\n",
       "      <td>9.1</td>\n",
       "      <td>2.54</td>\n",
       "      <td>33.02</td>\n",
       "      <td>1.778</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>2.8</td>\n",
       "      <td>10.16</td>\n",
       "      <td>1011.47</td>\n",
       "      <td>13.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Location_5</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.706123</td>\n",
       "      <td>145.126423</td>\n",
       "      <td>13</td>\n",
       "      <td>0.7</td>\n",
       "      <td>9.1</td>\n",
       "      <td>2.29</td>\n",
       "      <td>29.77</td>\n",
       "      <td>1.603</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>2.8</td>\n",
       "      <td>9.16</td>\n",
       "      <td>995.29</td>\n",
       "      <td>9.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  target   latitude   longitude  f1   f2   f3    f4     f5  \\\n",
       "0  Location_1       1 -37.706060  145.126555   6  1.5  9.0  7.33  43.98   \n",
       "1  Location_2       1 -37.706120  145.126457  11  0.8  8.8  3.52  38.72   \n",
       "2  Location_3       1 -37.706122  145.126435  12  0.7  8.4  2.93  35.16   \n",
       "3  Location_4       1 -37.706123  145.126427  13  0.7  9.1  2.54  33.02   \n",
       "4  Location_5       1 -37.706123  145.126423  13  0.7  9.1  2.29  29.77   \n",
       "\n",
       "       f6  f7  f8   f9    f10      f11    f12  \n",
       "0  10.995   2  12  3.0  14.66   999.62  17.48  \n",
       "1   2.816   3  33  2.4  10.56  1000.17  22.59  \n",
       "2   2.051   3  36  2.1   8.79   986.20  21.66  \n",
       "3   1.778   4  52  2.8  10.16  1011.47  13.72  \n",
       "4   1.603   4  52  2.8   9.16   995.29   9.19  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agersens_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4106295"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the length of the dataset\n",
    "len(agersens_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.106295e+06</td>\n",
       "      <td>3.877678e+06</td>\n",
       "      <td>4.106295e+06</td>\n",
       "      <td>4.106295e+06</td>\n",
       "      <td>4.106295e+06</td>\n",
       "      <td>3.101952e+06</td>\n",
       "      <td>4.106295e+06</td>\n",
       "      <td>4.073446e+06</td>\n",
       "      <td>4.106295e+06</td>\n",
       "      <td>4.106295e+06</td>\n",
       "      <td>4.106295e+06</td>\n",
       "      <td>4.106295e+06</td>\n",
       "      <td>4.098033e+06</td>\n",
       "      <td>4.106295e+06</td>\n",
       "      <td>4.106295e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.919292e-01</td>\n",
       "      <td>-3.770612e+01</td>\n",
       "      <td>1.451264e+02</td>\n",
       "      <td>1.508246e+01</td>\n",
       "      <td>7.535538e-01</td>\n",
       "      <td>1.031854e+01</td>\n",
       "      <td>1.866368e+00</td>\n",
       "      <td>1.962658e+01</td>\n",
       "      <td>2.419367e+00</td>\n",
       "      <td>2.868143e+02</td>\n",
       "      <td>5.175781e+03</td>\n",
       "      <td>1.716860e+02</td>\n",
       "      <td>1.582932e+02</td>\n",
       "      <td>9.999998e+02</td>\n",
       "      <td>1.999491e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.947426e-02</td>\n",
       "      <td>8.390644e-05</td>\n",
       "      <td>1.281560e-04</td>\n",
       "      <td>4.389738e+00</td>\n",
       "      <td>4.288497e-01</td>\n",
       "      <td>2.702694e+00</td>\n",
       "      <td>6.515952e+00</td>\n",
       "      <td>3.618669e+01</td>\n",
       "      <td>3.508119e+01</td>\n",
       "      <td>2.959106e+02</td>\n",
       "      <td>5.502739e+03</td>\n",
       "      <td>1.779611e+02</td>\n",
       "      <td>1.550168e+02</td>\n",
       "      <td>1.000328e+01</td>\n",
       "      <td>4.998535e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.773290e+01</td>\n",
       "      <td>1.450800e+02</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.800000e-01</td>\n",
       "      <td>3.480000e+00</td>\n",
       "      <td>1.960000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.514000e+02</td>\n",
       "      <td>-6.250000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-3.770613e+01</td>\n",
       "      <td>1.451264e+02</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>6.000000e-01</td>\n",
       "      <td>9.500000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.100000e+02</td>\n",
       "      <td>9.500000e+00</td>\n",
       "      <td>2.493000e+01</td>\n",
       "      <td>9.932400e+02</td>\n",
       "      <td>1.662000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-3.770612e+01</td>\n",
       "      <td>1.451264e+02</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>7.000000e-01</td>\n",
       "      <td>1.050000e+01</td>\n",
       "      <td>5.800000e-01</td>\n",
       "      <td>1.080000e+01</td>\n",
       "      <td>3.500000e-01</td>\n",
       "      <td>1.850000e+02</td>\n",
       "      <td>3.222000e+03</td>\n",
       "      <td>1.092000e+02</td>\n",
       "      <td>1.020800e+02</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.999000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-3.770611e+01</td>\n",
       "      <td>1.451264e+02</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>8.000000e-01</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>2.050000e+00</td>\n",
       "      <td>2.250000e+01</td>\n",
       "      <td>1.792000e+00</td>\n",
       "      <td>5.420000e+02</td>\n",
       "      <td>9.690000e+03</td>\n",
       "      <td>3.150000e+02</td>\n",
       "      <td>2.800000e+02</td>\n",
       "      <td>1.006750e+03</td>\n",
       "      <td>2.337000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-3.762418e+01</td>\n",
       "      <td>1.452322e+02</td>\n",
       "      <td>6.300000e+01</td>\n",
       "      <td>1.117000e+02</td>\n",
       "      <td>1.408000e+03</td>\n",
       "      <td>6.549600e+02</td>\n",
       "      <td>9.410550e+03</td>\n",
       "      <td>2.402215e+04</td>\n",
       "      <td>9.010000e+02</td>\n",
       "      <td>2.157600e+04</td>\n",
       "      <td>3.449600e+04</td>\n",
       "      <td>4.812372e+04</td>\n",
       "      <td>1.049120e+03</td>\n",
       "      <td>4.540000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             target      latitude     longitude            f1            f2  \\\n",
       "count  4.106295e+06  3.877678e+06  4.106295e+06  4.106295e+06  4.106295e+06   \n",
       "mean   9.919292e-01 -3.770612e+01  1.451264e+02  1.508246e+01  7.535538e-01   \n",
       "std    8.947426e-02  8.390644e-05  1.281560e-04  4.389738e+00  4.288497e-01   \n",
       "min    0.000000e+00 -3.773290e+01  1.450800e+02  3.000000e+00  4.000000e-01   \n",
       "25%    1.000000e+00 -3.770613e+01  1.451264e+02  1.100000e+01  6.000000e-01   \n",
       "50%    1.000000e+00 -3.770612e+01  1.451264e+02  1.600000e+01  7.000000e-01   \n",
       "75%    1.000000e+00 -3.770611e+01  1.451264e+02  1.900000e+01  8.000000e-01   \n",
       "max    1.000000e+00 -3.762418e+01  1.452322e+02  6.300000e+01  1.117000e+02   \n",
       "\n",
       "                 f3            f4            f5            f6            f7  \\\n",
       "count  3.101952e+06  4.106295e+06  4.073446e+06  4.106295e+06  4.106295e+06   \n",
       "mean   1.031854e+01  1.866368e+00  1.962658e+01  2.419367e+00  2.868143e+02   \n",
       "std    2.702694e+00  6.515952e+00  3.618669e+01  3.508119e+01  2.959106e+02   \n",
       "min    3.000000e+00  4.800000e-01  3.480000e+00  1.960000e-01  0.000000e+00   \n",
       "25%    9.500000e+00  5.000000e-01  9.000000e+00  3.000000e-01  1.000000e+01   \n",
       "50%    1.050000e+01  5.800000e-01  1.080000e+01  3.500000e-01  1.850000e+02   \n",
       "75%    1.100000e+01  2.050000e+00  2.250000e+01  1.792000e+00  5.420000e+02   \n",
       "max    1.408000e+03  6.549600e+02  9.410550e+03  2.402215e+04  9.010000e+02   \n",
       "\n",
       "                 f8            f9           f10           f11           f12  \n",
       "count  4.106295e+06  4.106295e+06  4.098033e+06  4.106295e+06  4.106295e+06  \n",
       "mean   5.175781e+03  1.716860e+02  1.582932e+02  9.999998e+02  1.999491e+01  \n",
       "std    5.502739e+03  1.779611e+02  1.550168e+02  1.000328e+01  4.998535e+00  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  9.514000e+02 -6.250000e+00  \n",
       "25%    1.100000e+02  9.500000e+00  2.493000e+01  9.932400e+02  1.662000e+01  \n",
       "50%    3.222000e+03  1.092000e+02  1.020800e+02  1.000000e+03  1.999000e+01  \n",
       "75%    9.690000e+03  3.150000e+02  2.800000e+02  1.006750e+03  2.337000e+01  \n",
       "max    2.157600e+04  3.449600e+04  4.812372e+04  1.049120e+03  4.540000e+01  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agersens_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4106295 entries, 0 to 4106294\n",
      "Data columns (total 16 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   ID         object \n",
      " 1   target     int64  \n",
      " 2   latitude   float64\n",
      " 3   longitude  float64\n",
      " 4   f1         int64  \n",
      " 5   f2         float64\n",
      " 6   f3         float64\n",
      " 7   f4         float64\n",
      " 8   f5         float64\n",
      " 9   f6         float64\n",
      " 10  f7         int64  \n",
      " 11  f8         int64  \n",
      " 12  f9         float64\n",
      " 13  f10        float64\n",
      " 14  f11        float64\n",
      " 15  f12        float64\n",
      "dtypes: float64(11), int64(4), object(1)\n",
      "memory usage: 501.3+ MB\n"
     ]
    }
   ],
   "source": [
    "agersens_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No categorical column present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                 0\n",
       "target             0\n",
       "latitude      228617\n",
       "longitude          0\n",
       "f1                 0\n",
       "f2                 0\n",
       "f3           1004343\n",
       "f4                 0\n",
       "f5             32849\n",
       "f6                 0\n",
       "f7                 0\n",
       "f8                 0\n",
       "f9                 0\n",
       "f10             8262\n",
       "f11                0\n",
       "f12                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agersens_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nulls in `latitude`, `f3`, `f5`, `f10`. \n",
    "\n",
    "Removing rows where `latitude` is null. As cannot impute values for geographical coordinates and we will only be losing 246 rows for `Non-Spurious` data, which is less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agersens_df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Location_36</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.126405</td>\n",
       "      <td>15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>16.35</td>\n",
       "      <td>0.654</td>\n",
       "      <td>20</td>\n",
       "      <td>300</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.80</td>\n",
       "      <td>987.39</td>\n",
       "      <td>13.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Location_37</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.126405</td>\n",
       "      <td>15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>16.05</td>\n",
       "      <td>0.642</td>\n",
       "      <td>20</td>\n",
       "      <td>300</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.40</td>\n",
       "      <td>1024.25</td>\n",
       "      <td>21.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Location_38</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.126405</td>\n",
       "      <td>15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>15.90</td>\n",
       "      <td>0.636</td>\n",
       "      <td>21</td>\n",
       "      <td>315</td>\n",
       "      <td>12.6</td>\n",
       "      <td>22.26</td>\n",
       "      <td>999.15</td>\n",
       "      <td>24.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Location_39</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.126405</td>\n",
       "      <td>15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>15.75</td>\n",
       "      <td>0.630</td>\n",
       "      <td>21</td>\n",
       "      <td>315</td>\n",
       "      <td>12.6</td>\n",
       "      <td>22.05</td>\n",
       "      <td>1012.19</td>\n",
       "      <td>18.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Location_40</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.126405</td>\n",
       "      <td>15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.04</td>\n",
       "      <td>15.60</td>\n",
       "      <td>0.624</td>\n",
       "      <td>22</td>\n",
       "      <td>330</td>\n",
       "      <td>13.2</td>\n",
       "      <td>22.88</td>\n",
       "      <td>979.04</td>\n",
       "      <td>21.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105830</th>\n",
       "      <td>Location_4105831</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.126300</td>\n",
       "      <td>8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.83</td>\n",
       "      <td>38.64</td>\n",
       "      <td>5.796</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>2.4</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1006.41</td>\n",
       "      <td>23.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105831</th>\n",
       "      <td>Location_4105832</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.126300</td>\n",
       "      <td>11</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.9</td>\n",
       "      <td>4.10</td>\n",
       "      <td>45.10</td>\n",
       "      <td>3.690</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>2.7</td>\n",
       "      <td>12.30</td>\n",
       "      <td>998.45</td>\n",
       "      <td>20.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106170</th>\n",
       "      <td>Location_4106171</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.126400</td>\n",
       "      <td>15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.97</td>\n",
       "      <td>14.55</td>\n",
       "      <td>0.679</td>\n",
       "      <td>60</td>\n",
       "      <td>900</td>\n",
       "      <td>42.0</td>\n",
       "      <td>58.20</td>\n",
       "      <td>978.37</td>\n",
       "      <td>22.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106171</th>\n",
       "      <td>Location_4106172</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.126400</td>\n",
       "      <td>15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.97</td>\n",
       "      <td>14.55</td>\n",
       "      <td>0.679</td>\n",
       "      <td>61</td>\n",
       "      <td>915</td>\n",
       "      <td>42.7</td>\n",
       "      <td>59.17</td>\n",
       "      <td>1000.23</td>\n",
       "      <td>20.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106289</th>\n",
       "      <td>Location_4106290</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.126400</td>\n",
       "      <td>13</td>\n",
       "      <td>0.9</td>\n",
       "      <td>11.7</td>\n",
       "      <td>2.31</td>\n",
       "      <td>30.03</td>\n",
       "      <td>2.079</td>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "      <td>4.5</td>\n",
       "      <td>11.55</td>\n",
       "      <td>994.67</td>\n",
       "      <td>22.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228617 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID  target  latitude   longitude  f1   f2    f3    f4  \\\n",
       "35            Location_36       1       NaN  145.126405  15  0.6   9.0  1.09   \n",
       "36            Location_37       1       NaN  145.126405  15  0.6   9.0  1.07   \n",
       "37            Location_38       1       NaN  145.126405  15  0.6   9.0  1.06   \n",
       "38            Location_39       1       NaN  145.126405  15  0.6   9.0  1.05   \n",
       "39            Location_40       1       NaN  145.126405  15  0.6   9.0  1.04   \n",
       "...                   ...     ...       ...         ...  ..  ...   ...   ...   \n",
       "4105830  Location_4105831       1       NaN  145.126300   8  1.2   NaN  4.83   \n",
       "4105831  Location_4105832       1       NaN  145.126300  11  0.9   9.9  4.10   \n",
       "4106170  Location_4106171       1       NaN  145.126400  15  0.7  10.5  0.97   \n",
       "4106171  Location_4106172       1       NaN  145.126400  15  0.7  10.5  0.97   \n",
       "4106289  Location_4106290       1       NaN  145.126400  13  0.9  11.7  2.31   \n",
       "\n",
       "            f5     f6  f7   f8    f9    f10      f11    f12  \n",
       "35       16.35  0.654  20  300  12.0  21.80   987.39  13.24  \n",
       "36       16.05  0.642  20  300  12.0  21.40  1024.25  21.07  \n",
       "37       15.90  0.636  21  315  12.6  22.26   999.15  24.53  \n",
       "38       15.75  0.630  21  315  12.6  22.05  1012.19  18.90  \n",
       "39       15.60  0.624  22  330  13.2  22.88   979.04  21.48  \n",
       "...        ...    ...  ..  ...   ...    ...      ...    ...  \n",
       "4105830  38.64  5.796   2   16   2.4   9.66  1006.41  23.38  \n",
       "4105831  45.10  3.690   3   33   2.7  12.30   998.45  20.13  \n",
       "4106170  14.55  0.679  60  900  42.0  58.20   978.37  22.41  \n",
       "4106171  14.55  0.679  61  915  42.7  59.17  1000.23  20.01  \n",
       "4106289  30.03  2.079   5   65   4.5  11.55   994.67  22.92  \n",
       "\n",
       "[228617 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agersens_df[agersens_df['latitude'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3877678"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agersens_df) - len(agersens_df[agersens_df['latitude'].isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only 0.8% of the data is `Non-Spurious`\n",
    "\n",
    "The data is highly imbalanced, we have to be careful in removing records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4073154\n",
       "0      33141\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agersens_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.991929\n",
       "0    0.008071\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agersens_df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing missing values for `f3` with the mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agersens_df['f3'] = agersens_df['f3'].fillna(agersens_df['f3'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                0\n",
       "target            0\n",
       "latitude     228617\n",
       "longitude         0\n",
       "f1                0\n",
       "f2                0\n",
       "f3                0\n",
       "f4                0\n",
       "f5            32849\n",
       "f6                0\n",
       "f7                0\n",
       "f8                0\n",
       "f9                0\n",
       "f10            8262\n",
       "f11               0\n",
       "f12               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agersens_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4106295"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agersens_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing rows where null value is present in any column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "agersens_df = agersens_df.dropna(axis=0, how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "target       0\n",
       "latitude     0\n",
       "longitude    0\n",
       "f1           0\n",
       "f2           0\n",
       "f3           0\n",
       "f4           0\n",
       "f5           0\n",
       "f6           0\n",
       "f7           0\n",
       "f8           0\n",
       "f9           0\n",
       "f10          0\n",
       "f11          0\n",
       "f12          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agersens_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3839172"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agersens_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3806293\n",
       "0      32879\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agersens_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'target', 'latitude', 'longitude', 'f1', 'f2', 'f3', 'f4', 'f5',\n",
       "       'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agersens_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the number of rows for each column beyond a threshold value using z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping records less than 3rd standard deviation from columns: `f1`, `f9`, `f11` and `f12`\n",
    "\n",
    "This is done based on the analysis done in `agersens_data_analysis.ipynb` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_agersens_df = agersens_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping records which lie within the 3rd standard deviation using z-score\n",
    "upd_agersens_df = upd_agersens_df[(np.abs(stats.zscore(upd_agersens_df['f1'])) < 3)]\n",
    "upd_agersens_df = upd_agersens_df[(np.abs(stats.zscore(upd_agersens_df['f9'])) < 3)]\n",
    "upd_agersens_df = upd_agersens_df[(np.abs(stats.zscore(upd_agersens_df['f11'])) < 3)]\n",
    "upd_agersens_df = upd_agersens_df[(np.abs(stats.zscore(upd_agersens_df['f12'])) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3815118"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(upd_agersens_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3782409\n",
       "0      32709\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_agersens_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### creating a new column combining the latitude and longitude columns\n",
    "\n",
    "(Might use it as a categorical column, will remove it otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_agersens_df['coordinates'] = upd_agersens_df['latitude'].astype(str) + \", \" + upd_agersens_df['longitude'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Location_1</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.706060</td>\n",
       "      <td>145.126555</td>\n",
       "      <td>6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.33</td>\n",
       "      <td>43.98</td>\n",
       "      <td>10.995</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.66</td>\n",
       "      <td>999.62</td>\n",
       "      <td>17.48</td>\n",
       "      <td>-37.70606, 145.126555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Location_2</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.706120</td>\n",
       "      <td>145.126457</td>\n",
       "      <td>11</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.52</td>\n",
       "      <td>38.72</td>\n",
       "      <td>2.816</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>2.4</td>\n",
       "      <td>10.56</td>\n",
       "      <td>1000.17</td>\n",
       "      <td>22.59</td>\n",
       "      <td>-37.70612, 145.126456667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Location_3</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.706122</td>\n",
       "      <td>145.126435</td>\n",
       "      <td>12</td>\n",
       "      <td>0.7</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.93</td>\n",
       "      <td>35.16</td>\n",
       "      <td>2.051</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>2.1</td>\n",
       "      <td>8.79</td>\n",
       "      <td>986.20</td>\n",
       "      <td>21.66</td>\n",
       "      <td>-37.706121667, 145.12643500000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Location_4</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.706123</td>\n",
       "      <td>145.126427</td>\n",
       "      <td>13</td>\n",
       "      <td>0.7</td>\n",
       "      <td>9.1</td>\n",
       "      <td>2.54</td>\n",
       "      <td>33.02</td>\n",
       "      <td>1.778</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>2.8</td>\n",
       "      <td>10.16</td>\n",
       "      <td>1011.47</td>\n",
       "      <td>13.72</td>\n",
       "      <td>-37.706123333, 145.126426667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Location_5</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.706123</td>\n",
       "      <td>145.126423</td>\n",
       "      <td>13</td>\n",
       "      <td>0.7</td>\n",
       "      <td>9.1</td>\n",
       "      <td>2.29</td>\n",
       "      <td>29.77</td>\n",
       "      <td>1.603</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>2.8</td>\n",
       "      <td>9.16</td>\n",
       "      <td>995.29</td>\n",
       "      <td>9.19</td>\n",
       "      <td>-37.706123333, 145.126423333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  target   latitude   longitude  f1   f2   f3    f4     f5  \\\n",
       "0  Location_1       1 -37.706060  145.126555   6  1.5  9.0  7.33  43.98   \n",
       "1  Location_2       1 -37.706120  145.126457  11  0.8  8.8  3.52  38.72   \n",
       "2  Location_3       1 -37.706122  145.126435  12  0.7  8.4  2.93  35.16   \n",
       "3  Location_4       1 -37.706123  145.126427  13  0.7  9.1  2.54  33.02   \n",
       "4  Location_5       1 -37.706123  145.126423  13  0.7  9.1  2.29  29.77   \n",
       "\n",
       "       f6  f7  f8   f9    f10      f11    f12  \\\n",
       "0  10.995   2  12  3.0  14.66   999.62  17.48   \n",
       "1   2.816   3  33  2.4  10.56  1000.17  22.59   \n",
       "2   2.051   3  36  2.1   8.79   986.20  21.66   \n",
       "3   1.778   4  52  2.8  10.16  1011.47  13.72   \n",
       "4   1.603   4  52  2.8   9.16   995.29   9.19   \n",
       "\n",
       "                         coordinates  \n",
       "0              -37.70606, 145.126555  \n",
       "1           -37.70612, 145.126456667  \n",
       "2  -37.706121667, 145.12643500000001  \n",
       "3       -37.706123333, 145.126426667  \n",
       "4       -37.706123333, 145.126423333  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd_agersens_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3815118"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(upd_agersens_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4431"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(upd_agersens_df['coordinates'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new dataframe and dropping the ID and coordinates column\n",
    "full_upd_agersens_df = upd_agersens_df.drop(['ID', 'coordinates'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'latitude', 'longitude', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6',\n",
       "       'f7', 'f8', 'f9', 'f10', 'f11', 'f12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_upd_agersens_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling certain columns using MinMax Scaler\n",
    "\n",
    "Using MinMax Scaler as either I have removed outliers from them or there were none to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "minmax_columns = ['f1', 'f7', 'f8', 'f9', 'f11', 'f12']\n",
    "\n",
    "full_upd_agersens_df[minmax_columns] = minmax_scaler.fit_transform(full_upd_agersens_df[minmax_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling certain columns using Robust Scaler\n",
    "\n",
    "Using Robust scaler as there were certain columns where removing rows with outliers can lead to losing out on a lot of `Non-Spurious` data, this will consider outliers during scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler = RobustScaler()\n",
    "\n",
    "robust_columns = ['f2', 'f3', 'f4', 'f5', 'f6', 'f10']\n",
    "\n",
    "full_upd_agersens_df[robust_columns] = robust_scaler.fit_transform(full_upd_agersens_df[robust_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-37.706060</td>\n",
       "      <td>145.126555</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.318543</td>\n",
       "      <td>4.299363</td>\n",
       "      <td>2.404364</td>\n",
       "      <td>7.012516</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>-0.332224</td>\n",
       "      <td>0.493669</td>\n",
       "      <td>0.416139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-37.706120</td>\n",
       "      <td>145.126457</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.518543</td>\n",
       "      <td>1.872611</td>\n",
       "      <td>2.021818</td>\n",
       "      <td>1.624506</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>-0.348470</td>\n",
       "      <td>0.502832</td>\n",
       "      <td>0.586529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-37.706122</td>\n",
       "      <td>145.126435</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.918543</td>\n",
       "      <td>1.496815</td>\n",
       "      <td>1.762909</td>\n",
       "      <td>1.120553</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>-0.355484</td>\n",
       "      <td>0.270077</td>\n",
       "      <td>0.555519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-37.706123</td>\n",
       "      <td>145.126427</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.218543</td>\n",
       "      <td>1.248408</td>\n",
       "      <td>1.607273</td>\n",
       "      <td>0.940711</td>\n",
       "      <td>0.00444</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>-0.350055</td>\n",
       "      <td>0.691103</td>\n",
       "      <td>0.290764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-37.706123</td>\n",
       "      <td>145.126423</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.218543</td>\n",
       "      <td>1.089172</td>\n",
       "      <td>1.370909</td>\n",
       "      <td>0.825428</td>\n",
       "      <td>0.00444</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>-0.354018</td>\n",
       "      <td>0.421526</td>\n",
       "      <td>0.139713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target   latitude   longitude        f1   f2        f3        f4        f5  \\\n",
       "0       1 -37.706060  145.126555  0.142857  4.0 -1.318543  4.299363  2.404364   \n",
       "1       1 -37.706120  145.126457  0.380952  0.5 -1.518543  1.872611  2.021818   \n",
       "2       1 -37.706122  145.126435  0.428571  0.0 -1.918543  1.496815  1.762909   \n",
       "3       1 -37.706123  145.126427  0.476190  0.0 -1.218543  1.248408  1.607273   \n",
       "4       1 -37.706123  145.126423  0.476190  0.0 -1.218543  1.089172  1.370909   \n",
       "\n",
       "         f6       f7        f8        f9       f10       f11       f12  \n",
       "0  7.012516  0.00222  0.000556  0.004274 -0.332224  0.493669  0.416139  \n",
       "1  1.624506  0.00333  0.001529  0.003419 -0.348470  0.502832  0.586529  \n",
       "2  1.120553  0.00333  0.001669  0.002991 -0.355484  0.270077  0.555519  \n",
       "3  0.940711  0.00444  0.002410  0.003989 -0.350055  0.691103  0.290764  \n",
       "4  0.825428  0.00444  0.002410  0.003989 -0.354018  0.421526  0.139713  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_upd_agersens_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating metrics after downsampling the data and running different models and generating metrics for different random states\n",
    "\n",
    "Generating metrics like `Accuracy`, `F1Score` and `Confusion Matrix` for different random states, to see the reliability of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_random_state_df = pd.DataFrame(\n",
    "    {'run_id': list(range(0, 10)),\n",
    "     'random_state': list(range(0, 10))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "train_f1_list = []\n",
    "test_f1_list = []\n",
    "train_true_pos_list = []\n",
    "train_false_pos_list = []\n",
    "train_false_neg_list = []\n",
    "train_true_neg_list = []\n",
    "test_true_pos_list = []\n",
    "test_false_pos_list = []\n",
    "test_false_neg_list = []\n",
    "test_true_neg_list = []\n",
    "\n",
    "\n",
    "for j in range(10):\n",
    "    \n",
    "    shufled_agersens_df = full_upd_agersens_df.sample(frac=1, random_state=j).reset_index(drop=True)\n",
    "    \n",
    "    X = shufled_agersens_df.drop(columns=['target'])\n",
    "    y = shufled_agersens_df['target']\n",
    "\n",
    "    #split data into test and training sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=j)\n",
    "\n",
    "    #training part\n",
    "    #combine them back for resampling\n",
    "    train_data = pd.concat([X_train, y_train], axis=1)\n",
    "    \n",
    "    # separate minority and majority classes\n",
    "    negative = train_data[train_data['target']==1]\n",
    "    positive = train_data[train_data['target']==0]\n",
    "\n",
    "    # downsample majority\n",
    "    neg_downsampled = resample(negative,\n",
    "     replace=True, # sample with replacement\n",
    "     n_samples=len(positive), # match number in minority class\n",
    "     random_state=j) # reproducible results\n",
    "    # combine minority and downsampled majority\n",
    "    train_downsampled = pd.concat([positive, neg_downsampled])\n",
    "\n",
    "    #testing part\n",
    "    #combine them back for resampling\n",
    "    test_data = pd.concat([X_test, y_test], axis=1)\n",
    "    \n",
    "    # separate minority and majority classes\n",
    "    negative = test_data[test_data['target']==1]\n",
    "    positive = test_data[test_data['target']==0]\n",
    "\n",
    "    # downsample majority\n",
    "    neg_downsampled = resample(negative,\n",
    "     replace=True, # sample with replacement\n",
    "     n_samples=len(positive), # match number in minority class\n",
    "     random_state=j) # reproducible results\n",
    "    # combine minority and downsampled majority\n",
    "    test_downsampled = pd.concat([positive, neg_downsampled])\n",
    "\n",
    "\n",
    "    X_train = train_downsampled.drop(['target'],axis=1)\n",
    "\n",
    "    X_test =  test_downsampled.drop(['target'],axis=1)\n",
    "\n",
    "    y_train = train_downsampled['target']\n",
    "\n",
    "    y_test = test_downsampled['target']\n",
    "\n",
    "    svc_model = SVC(kernel='sigmoid')\n",
    "\n",
    "    svc_model.fit(X_train, y_train)\n",
    "\n",
    "    svc_train_preds = svc_model.predict(X_train)\n",
    "    svc_test_preds = svc_model.predict(X_test)\n",
    "\n",
    "    train_acc_svc = accuracy_score(y_train, svc_train_preds)\n",
    "    test_acc_svc = accuracy_score(y_test, svc_test_preds)\n",
    "    \n",
    "    train_f1_svc = f1_score(y_train, svc_train_preds)\n",
    "    test_f1_svc = f1_score(y_test, svc_test_preds)\n",
    "\n",
    "    train_conf_matrix_svc = confusion_matrix(y_train, svc_train_preds)\n",
    "    train_true_pos = train_conf_matrix_svc[0][0]\n",
    "    train_false_pos = train_conf_matrix_svc[0][1]\n",
    "    train_false_neg = train_conf_matrix_svc[1][0]\n",
    "    train_true_neg = train_conf_matrix_svc[1][1]\n",
    "    \n",
    "    test_conf_matrix_svc = confusion_matrix(y_test, svc_test_preds)\n",
    "    test_true_pos = test_conf_matrix_svc[0][0]\n",
    "    test_false_pos = test_conf_matrix_svc[0][1]\n",
    "    test_false_neg = test_conf_matrix_svc[1][0]\n",
    "    test_true_neg = test_conf_matrix_svc[1][1]   \n",
    "    \n",
    "    train_accuracy_list.append(train_acc_svc)\n",
    "    test_accuracy_list.append(test_acc_svc)\n",
    "    \n",
    "    train_f1_list.append(train_f1_svc)\n",
    "    test_f1_list.append(test_f1_svc)\n",
    "    \n",
    "    train_true_pos_list.append(train_true_pos)\n",
    "    train_false_pos_list.append(train_false_pos)    \n",
    "    train_false_neg_list.append(train_false_neg)\n",
    "    train_true_neg_list.append(train_true_neg)\n",
    "    \n",
    "    test_true_pos_list.append(test_true_pos)\n",
    "    test_false_pos_list.append(test_false_pos)    \n",
    "    test_false_neg_list.append(test_false_neg)\n",
    "    test_true_neg_list.append(test_true_neg)\n",
    "    \n",
    "svc_random_state_df['train_accuracy'] = train_accuracy_list\n",
    "svc_random_state_df['test_accuracy'] = test_accuracy_list\n",
    "svc_random_state_df['train_f1_score'] = train_f1_list\n",
    "svc_random_state_df['test_f1_score'] = test_f1_list\n",
    "svc_random_state_df['train_true_pos'] = train_true_pos_list\n",
    "svc_random_state_df['train_false_pos'] = train_false_pos_list\n",
    "svc_random_state_df['train_false_neg'] = train_false_neg_list\n",
    "svc_random_state_df['train_true_neg'] = train_true_neg_list\n",
    "svc_random_state_df['test_true_pos'] = test_true_pos_list\n",
    "svc_random_state_df['test_false_pos'] = test_false_pos_list\n",
    "svc_random_state_df['test_false_neg'] = test_false_neg_list\n",
    "svc_random_state_df['test_true_neg'] = test_true_neg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>train_true_pos</th>\n",
       "      <th>train_false_pos</th>\n",
       "      <th>train_false_neg</th>\n",
       "      <th>train_true_neg</th>\n",
       "      <th>test_true_pos</th>\n",
       "      <th>test_false_pos</th>\n",
       "      <th>test_false_neg</th>\n",
       "      <th>test_true_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.926961</td>\n",
       "      <td>0.924859</td>\n",
       "      <td>0.929362</td>\n",
       "      <td>0.927700</td>\n",
       "      <td>20515</td>\n",
       "      <td>2459</td>\n",
       "      <td>897</td>\n",
       "      <td>22077</td>\n",
       "      <td>8621</td>\n",
       "      <td>1114</td>\n",
       "      <td>349</td>\n",
       "      <td>9386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.935658</td>\n",
       "      <td>0.935260</td>\n",
       "      <td>0.935672</td>\n",
       "      <td>0.935191</td>\n",
       "      <td>21357</td>\n",
       "      <td>1474</td>\n",
       "      <td>1464</td>\n",
       "      <td>21367</td>\n",
       "      <td>9249</td>\n",
       "      <td>629</td>\n",
       "      <td>650</td>\n",
       "      <td>9228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.933728</td>\n",
       "      <td>0.935024</td>\n",
       "      <td>0.933732</td>\n",
       "      <td>0.935048</td>\n",
       "      <td>21393</td>\n",
       "      <td>1520</td>\n",
       "      <td>1517</td>\n",
       "      <td>21396</td>\n",
       "      <td>9156</td>\n",
       "      <td>640</td>\n",
       "      <td>633</td>\n",
       "      <td>9163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.934320</td>\n",
       "      <td>0.936520</td>\n",
       "      <td>0.934338</td>\n",
       "      <td>0.936451</td>\n",
       "      <td>21495</td>\n",
       "      <td>1518</td>\n",
       "      <td>1505</td>\n",
       "      <td>21508</td>\n",
       "      <td>9091</td>\n",
       "      <td>605</td>\n",
       "      <td>626</td>\n",
       "      <td>9070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.934541</td>\n",
       "      <td>0.936602</td>\n",
       "      <td>0.934516</td>\n",
       "      <td>0.936550</td>\n",
       "      <td>21467</td>\n",
       "      <td>1494</td>\n",
       "      <td>1512</td>\n",
       "      <td>21449</td>\n",
       "      <td>9138</td>\n",
       "      <td>610</td>\n",
       "      <td>626</td>\n",
       "      <td>9122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.937377</td>\n",
       "      <td>0.931791</td>\n",
       "      <td>0.937360</td>\n",
       "      <td>0.931925</td>\n",
       "      <td>21411</td>\n",
       "      <td>1424</td>\n",
       "      <td>1436</td>\n",
       "      <td>21399</td>\n",
       "      <td>9181</td>\n",
       "      <td>693</td>\n",
       "      <td>654</td>\n",
       "      <td>9220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.927362</td>\n",
       "      <td>0.926079</td>\n",
       "      <td>0.929771</td>\n",
       "      <td>0.928624</td>\n",
       "      <td>20458</td>\n",
       "      <td>2450</td>\n",
       "      <td>878</td>\n",
       "      <td>22030</td>\n",
       "      <td>8727</td>\n",
       "      <td>1074</td>\n",
       "      <td>375</td>\n",
       "      <td>9426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.934265</td>\n",
       "      <td>0.935494</td>\n",
       "      <td>0.934216</td>\n",
       "      <td>0.935709</td>\n",
       "      <td>21350</td>\n",
       "      <td>1484</td>\n",
       "      <td>1518</td>\n",
       "      <td>21316</td>\n",
       "      <td>9205</td>\n",
       "      <td>670</td>\n",
       "      <td>604</td>\n",
       "      <td>9271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.935744</td>\n",
       "      <td>0.934386</td>\n",
       "      <td>0.935733</td>\n",
       "      <td>0.934500</td>\n",
       "      <td>21484</td>\n",
       "      <td>1471</td>\n",
       "      <td>1479</td>\n",
       "      <td>21476</td>\n",
       "      <td>9097</td>\n",
       "      <td>657</td>\n",
       "      <td>623</td>\n",
       "      <td>9131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.932910</td>\n",
       "      <td>0.936148</td>\n",
       "      <td>0.932893</td>\n",
       "      <td>0.936306</td>\n",
       "      <td>21462</td>\n",
       "      <td>1537</td>\n",
       "      <td>1549</td>\n",
       "      <td>21450</td>\n",
       "      <td>9066</td>\n",
       "      <td>644</td>\n",
       "      <td>596</td>\n",
       "      <td>9114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id  random_state  train_accuracy  test_accuracy  train_f1_score  \\\n",
       "0       0             0        0.926961       0.924859        0.929362   \n",
       "1       1             1        0.935658       0.935260        0.935672   \n",
       "2       2             2        0.933728       0.935024        0.933732   \n",
       "3       3             3        0.934320       0.936520        0.934338   \n",
       "4       4             4        0.934541       0.936602        0.934516   \n",
       "5       5             5        0.937377       0.931791        0.937360   \n",
       "6       6             6        0.927362       0.926079        0.929771   \n",
       "7       7             7        0.934265       0.935494        0.934216   \n",
       "8       8             8        0.935744       0.934386        0.935733   \n",
       "9       9             9        0.932910       0.936148        0.932893   \n",
       "\n",
       "   test_f1_score  train_true_pos  train_false_pos  train_false_neg  \\\n",
       "0       0.927700           20515             2459              897   \n",
       "1       0.935191           21357             1474             1464   \n",
       "2       0.935048           21393             1520             1517   \n",
       "3       0.936451           21495             1518             1505   \n",
       "4       0.936550           21467             1494             1512   \n",
       "5       0.931925           21411             1424             1436   \n",
       "6       0.928624           20458             2450              878   \n",
       "7       0.935709           21350             1484             1518   \n",
       "8       0.934500           21484             1471             1479   \n",
       "9       0.936306           21462             1537             1549   \n",
       "\n",
       "   train_true_neg  test_true_pos  test_false_pos  test_false_neg  \\\n",
       "0           22077           8621            1114             349   \n",
       "1           21367           9249             629             650   \n",
       "2           21396           9156             640             633   \n",
       "3           21508           9091             605             626   \n",
       "4           21449           9138             610             626   \n",
       "5           21399           9181             693             654   \n",
       "6           22030           8727            1074             375   \n",
       "7           21316           9205             670             604   \n",
       "8           21476           9097             657             623   \n",
       "9           21450           9066             644             596   \n",
       "\n",
       "   test_true_neg  \n",
       "0           9386  \n",
       "1           9228  \n",
       "2           9163  \n",
       "3           9070  \n",
       "4           9122  \n",
       "5           9220  \n",
       "6           9426  \n",
       "7           9271  \n",
       "8           9131  \n",
       "9           9114  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_random_state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_random_state_df = pd.DataFrame(\n",
    "    {'run_id': list(range(0, 10)),\n",
    "     'random_state': list(range(0, 10))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "train_f1_list = []\n",
    "test_f1_list = []\n",
    "train_true_pos_list = []\n",
    "train_false_pos_list = []\n",
    "train_false_neg_list = []\n",
    "train_true_neg_list = []\n",
    "test_true_pos_list = []\n",
    "test_false_pos_list = []\n",
    "test_false_neg_list = []\n",
    "test_true_neg_list = []\n",
    "\n",
    "\n",
    "for j in range(10):\n",
    "    \n",
    "    shufled_agersens_df = full_upd_agersens_df.sample(frac=1, random_state=j).reset_index(drop=True)\n",
    "    \n",
    "    X = shufled_agersens_df.drop(columns=['target'])\n",
    "    y = shufled_agersens_df['target']\n",
    "\n",
    "    #split data into test and training sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=j)\n",
    "\n",
    "    #training part\n",
    "    #combine them back for resampling\n",
    "    train_data = pd.concat([X_train, y_train], axis=1)\n",
    "    \n",
    "    # separate minority and majority classes\n",
    "    negative = train_data[train_data['target']==1]\n",
    "    positive = train_data[train_data['target']==0]\n",
    "\n",
    "    # downsample majority\n",
    "    neg_downsampled = resample(negative,\n",
    "     replace=True, # sample with replacement\n",
    "     n_samples=len(positive), # match number in minority class\n",
    "     random_state=j) # reproducible results\n",
    "    # combine minority and downsampled majority\n",
    "    train_downsampled = pd.concat([positive, neg_downsampled])\n",
    "\n",
    "    #testing part\n",
    "    #combine them back for resampling\n",
    "    test_data = pd.concat([X_test, y_test], axis=1)\n",
    "    \n",
    "    # separate minority and majority classes\n",
    "    negative = test_data[test_data['target']==1]\n",
    "    positive = test_data[test_data['target']==0]\n",
    "\n",
    "    # downsample majority\n",
    "    neg_downsampled = resample(negative,\n",
    "     replace=True, # sample with replacement\n",
    "     n_samples=len(positive), # match number in minority class\n",
    "     random_state=j) # reproducible results\n",
    "    # combine minority and downsampled majority\n",
    "    test_downsampled = pd.concat([positive, neg_downsampled])\n",
    "\n",
    "\n",
    "    X_train = train_downsampled.drop(['target'],axis=1)\n",
    "\n",
    "    X_test =  test_downsampled.drop(['target'],axis=1)\n",
    "\n",
    "    y_train = train_downsampled['target']\n",
    "\n",
    "    y_test = test_downsampled['target']\n",
    "\n",
    "    rfc_model = RandomForestClassifier(max_depth = 12, max_features = 'sqrt')\n",
    "\n",
    "    rfc_model.fit(X_train, y_train)\n",
    "\n",
    "    rfc_train_preds = rfc_model.predict(X_train)\n",
    "    rfc_test_preds = rfc_model.predict(X_test)\n",
    "\n",
    "    train_acc_rfc = accuracy_score(y_train, rfc_train_preds)\n",
    "    test_acc_rfc = accuracy_score(y_test, rfc_test_preds)\n",
    "    \n",
    "    train_f1_rfc = f1_score(y_train, rfc_train_preds)\n",
    "    test_f1_rfc = f1_score(y_test, rfc_test_preds)\n",
    "\n",
    "    train_conf_matrix_rfc = confusion_matrix(y_train, rfc_train_preds)\n",
    "    train_true_pos = train_conf_matrix_rfc[0][0]\n",
    "    train_false_pos = train_conf_matrix_rfc[0][1]\n",
    "    train_false_neg = train_conf_matrix_rfc[1][0]\n",
    "    train_true_neg = train_conf_matrix_rfc[1][1]\n",
    "    \n",
    "    test_conf_matrix_rfc = confusion_matrix(y_test, rfc_test_preds)\n",
    "    test_true_pos = test_conf_matrix_rfc[0][0]\n",
    "    test_false_pos = test_conf_matrix_rfc[0][1]\n",
    "    test_false_neg = test_conf_matrix_rfc[1][0]\n",
    "    test_true_neg = test_conf_matrix_rfc[1][1]   \n",
    "    \n",
    "    train_accuracy_list.append(train_acc_rfc)\n",
    "    test_accuracy_list.append(test_acc_rfc)\n",
    "    \n",
    "    train_f1_list.append(train_f1_rfc)\n",
    "    test_f1_list.append(test_f1_rfc)\n",
    "    \n",
    "    train_true_pos_list.append(train_true_pos)\n",
    "    train_false_pos_list.append(train_false_pos)    \n",
    "    train_false_neg_list.append(train_false_neg)\n",
    "    train_true_neg_list.append(train_true_neg)\n",
    "    \n",
    "    test_true_pos_list.append(test_true_pos)\n",
    "    test_false_pos_list.append(test_false_pos)    \n",
    "    test_false_neg_list.append(test_false_neg)\n",
    "    test_true_neg_list.append(test_true_neg)\n",
    "    \n",
    "rfc_random_state_df['train_accuracy'] = train_accuracy_list\n",
    "rfc_random_state_df['test_accuracy'] = test_accuracy_list\n",
    "rfc_random_state_df['train_f1_score'] = train_f1_list\n",
    "rfc_random_state_df['test_f1_score'] = test_f1_list\n",
    "rfc_random_state_df['train_true_pos'] = train_true_pos_list\n",
    "rfc_random_state_df['train_false_pos'] = train_false_pos_list\n",
    "rfc_random_state_df['train_false_neg'] = train_false_neg_list\n",
    "rfc_random_state_df['train_true_neg'] = train_true_neg_list\n",
    "rfc_random_state_df['test_true_pos'] = test_true_pos_list\n",
    "rfc_random_state_df['test_false_pos'] = test_false_pos_list\n",
    "rfc_random_state_df['test_false_neg'] = test_false_neg_list\n",
    "rfc_random_state_df['test_true_neg'] = test_true_neg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>train_true_pos</th>\n",
       "      <th>train_false_pos</th>\n",
       "      <th>train_false_neg</th>\n",
       "      <th>train_true_neg</th>\n",
       "      <th>test_true_pos</th>\n",
       "      <th>test_false_pos</th>\n",
       "      <th>test_false_neg</th>\n",
       "      <th>test_true_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993057</td>\n",
       "      <td>0.988392</td>\n",
       "      <td>0.993009</td>\n",
       "      <td>0.988256</td>\n",
       "      <td>22974</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "      <td>22655</td>\n",
       "      <td>9735</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>9509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994722</td>\n",
       "      <td>0.989117</td>\n",
       "      <td>0.994694</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>22831</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>22590</td>\n",
       "      <td>9876</td>\n",
       "      <td>2</td>\n",
       "      <td>213</td>\n",
       "      <td>9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.993061</td>\n",
       "      <td>0.987291</td>\n",
       "      <td>0.993012</td>\n",
       "      <td>0.987131</td>\n",
       "      <td>22913</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "      <td>22595</td>\n",
       "      <td>9793</td>\n",
       "      <td>3</td>\n",
       "      <td>246</td>\n",
       "      <td>9550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.994394</td>\n",
       "      <td>0.990305</td>\n",
       "      <td>0.994363</td>\n",
       "      <td>0.990211</td>\n",
       "      <td>23013</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>22755</td>\n",
       "      <td>9695</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>9509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.992553</td>\n",
       "      <td>0.987895</td>\n",
       "      <td>0.992497</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>22961</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>22619</td>\n",
       "      <td>9747</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>9513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.993212</td>\n",
       "      <td>0.988505</td>\n",
       "      <td>0.993166</td>\n",
       "      <td>0.988374</td>\n",
       "      <td>22835</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>22525</td>\n",
       "      <td>9872</td>\n",
       "      <td>2</td>\n",
       "      <td>225</td>\n",
       "      <td>9649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.992906</td>\n",
       "      <td>0.988624</td>\n",
       "      <td>0.992856</td>\n",
       "      <td>0.988494</td>\n",
       "      <td>22908</td>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "      <td>22583</td>\n",
       "      <td>9800</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>9579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.993080</td>\n",
       "      <td>0.987595</td>\n",
       "      <td>0.993032</td>\n",
       "      <td>0.987440</td>\n",
       "      <td>22834</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>22518</td>\n",
       "      <td>9874</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "      <td>9631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.993139</td>\n",
       "      <td>0.989133</td>\n",
       "      <td>0.993091</td>\n",
       "      <td>0.989014</td>\n",
       "      <td>22955</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>22640</td>\n",
       "      <td>9753</td>\n",
       "      <td>1</td>\n",
       "      <td>211</td>\n",
       "      <td>9543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.992761</td>\n",
       "      <td>0.988414</td>\n",
       "      <td>0.992708</td>\n",
       "      <td>0.988279</td>\n",
       "      <td>22999</td>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "      <td>22666</td>\n",
       "      <td>9709</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "      <td>9486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id  random_state  train_accuracy  test_accuracy  train_f1_score  \\\n",
       "0       0             0        0.993057       0.988392        0.993009   \n",
       "1       1             1        0.994722       0.989117        0.994694   \n",
       "2       2             2        0.993061       0.987291        0.993012   \n",
       "3       3             3        0.994394       0.990305        0.994363   \n",
       "4       4             4        0.992553       0.987895        0.992497   \n",
       "5       5             5        0.993212       0.988505        0.993166   \n",
       "6       6             6        0.992906       0.988624        0.992856   \n",
       "7       7             7        0.993080       0.987595        0.993032   \n",
       "8       8             8        0.993139       0.989133        0.993091   \n",
       "9       9             9        0.992761       0.988414        0.992708   \n",
       "\n",
       "   test_f1_score  train_true_pos  train_false_pos  train_false_neg  \\\n",
       "0       0.988256           22974                0              319   \n",
       "1       0.989000           22831                0              241   \n",
       "2       0.987131           22913                0              318   \n",
       "3       0.990211           23013                0              258   \n",
       "4       0.987748           22961                0              342   \n",
       "5       0.988374           22835                0              310   \n",
       "6       0.988494           22908                0              325   \n",
       "7       0.987440           22834                0              316   \n",
       "8       0.989014           22955                0              315   \n",
       "9       0.988279           22999                0              333   \n",
       "\n",
       "   train_true_neg  test_true_pos  test_false_pos  test_false_neg  \\\n",
       "0           22655           9735               0             226   \n",
       "1           22590           9876               2             213   \n",
       "2           22595           9793               3             246   \n",
       "3           22755           9695               1             187   \n",
       "4           22619           9747               1             235   \n",
       "5           22525           9872               2             225   \n",
       "6           22583           9800               1             222   \n",
       "7           22518           9874               1             244   \n",
       "8           22640           9753               1             211   \n",
       "9           22666           9709               1             224   \n",
       "\n",
       "   test_true_neg  \n",
       "0           9509  \n",
       "1           9665  \n",
       "2           9550  \n",
       "3           9509  \n",
       "4           9513  \n",
       "5           9649  \n",
       "6           9579  \n",
       "7           9631  \n",
       "8           9543  \n",
       "9           9486  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_random_state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_random_state_df = pd.DataFrame(\n",
    "    {'run_id': list(range(0, 10)),\n",
    "     'random_state': list(range(0, 10))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:16:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning:\n",
      "\n",
      "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:16:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning:\n",
      "\n",
      "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:16:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning:\n",
      "\n",
      "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:16:27] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning:\n",
      "\n",
      "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:16:29] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning:\n",
      "\n",
      "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:16:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning:\n",
      "\n",
      "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:16:33] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning:\n",
      "\n",
      "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:16:36] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning:\n",
      "\n",
      "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:16:38] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning:\n",
      "\n",
      "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:16:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning:\n",
      "\n",
      "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "train_f1_list = []\n",
    "test_f1_list = []\n",
    "train_true_pos_list = []\n",
    "train_false_pos_list = []\n",
    "train_false_neg_list = []\n",
    "train_true_neg_list = []\n",
    "test_true_pos_list = []\n",
    "test_false_pos_list = []\n",
    "test_false_neg_list = []\n",
    "test_true_neg_list = []\n",
    "\n",
    "\n",
    "for j in range(10):\n",
    "    \n",
    "    shufled_agersens_df = full_upd_agersens_df.sample(frac=1, random_state=j).reset_index(drop=True)\n",
    "    \n",
    "    X = shufled_agersens_df.drop(columns=['target'])\n",
    "    y = shufled_agersens_df['target']\n",
    "\n",
    "    #split data into test and training sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=j)\n",
    "\n",
    "    #training part\n",
    "    #combine them back for resampling\n",
    "    train_data = pd.concat([X_train, y_train], axis=1)\n",
    "    \n",
    "    # separate minority and majority classes\n",
    "    negative = train_data[train_data['target']==1]\n",
    "    positive = train_data[train_data['target']==0]\n",
    "\n",
    "    # downsample majority\n",
    "    neg_downsampled = resample(negative,\n",
    "     replace=True, # sample with replacement\n",
    "     n_samples=len(positive), # match number in minority class\n",
    "     random_state=j) # reproducible results\n",
    "    # combine minority and downsampled majority\n",
    "    train_downsampled = pd.concat([positive, neg_downsampled])\n",
    "\n",
    "    #testing part\n",
    "    #combine them back for resampling\n",
    "    test_data = pd.concat([X_test, y_test], axis=1)\n",
    "    \n",
    "    # separate minority and majority classes\n",
    "    negative = test_data[test_data['target']==1]\n",
    "    positive = test_data[test_data['target']==0]\n",
    "\n",
    "    # downsample majority\n",
    "    neg_downsampled = resample(negative,\n",
    "     replace=True, # sample with replacement\n",
    "     n_samples=len(positive), # match number in minority class\n",
    "     random_state=j) # reproducible results\n",
    "    # combine minority and downsampled majority\n",
    "    test_downsampled = pd.concat([positive, neg_downsampled])\n",
    "\n",
    "\n",
    "    X_train = train_downsampled.drop(['target'],axis=1)\n",
    "\n",
    "    X_test =  test_downsampled.drop(['target'],axis=1)\n",
    "\n",
    "    y_train = train_downsampled['target']\n",
    "\n",
    "    y_test = test_downsampled['target']\n",
    "\n",
    "    xgb_model = xg.XGBClassifier()\n",
    "\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    xgb_train_preds = xgb_model.predict(X_train)\n",
    "    xgb_test_preds = xgb_model.predict(X_test)\n",
    "\n",
    "    train_acc_xgb = accuracy_score(y_train, xgb_train_preds)\n",
    "    test_acc_xgb = accuracy_score(y_test, xgb_test_preds)\n",
    "    \n",
    "    train_f1_xgb = f1_score(y_train, xgb_train_preds)\n",
    "    test_f1_xgb = f1_score(y_test, xgb_test_preds)\n",
    "\n",
    "    train_conf_matrix_xgb = confusion_matrix(y_train, xgb_train_preds)\n",
    "    train_true_pos = train_conf_matrix_xgb[0][0]\n",
    "    train_false_pos = train_conf_matrix_xgb[0][1]\n",
    "    train_false_neg = train_conf_matrix_xgb[1][0]\n",
    "    train_true_neg = train_conf_matrix_xgb[1][1]\n",
    "    \n",
    "    test_conf_matrix_xgb = confusion_matrix(y_test, xgb_test_preds)\n",
    "    test_true_pos = test_conf_matrix_xgb[0][0]\n",
    "    test_false_pos = test_conf_matrix_xgb[0][1]\n",
    "    test_false_neg = test_conf_matrix_xgb[1][0]\n",
    "    test_true_neg = test_conf_matrix_xgb[1][1]   \n",
    "    \n",
    "    train_accuracy_list.append(train_acc_xgb)\n",
    "    test_accuracy_list.append(test_acc_xgb)\n",
    "    \n",
    "    train_f1_list.append(train_f1_xgb)\n",
    "    test_f1_list.append(test_f1_xgb)\n",
    "    \n",
    "    train_true_pos_list.append(train_true_pos)\n",
    "    train_false_pos_list.append(train_false_pos)    \n",
    "    train_false_neg_list.append(train_false_neg)\n",
    "    train_true_neg_list.append(train_true_neg)\n",
    "    \n",
    "    test_true_pos_list.append(test_true_pos)\n",
    "    test_false_pos_list.append(test_false_pos)    \n",
    "    test_false_neg_list.append(test_false_neg)\n",
    "    test_true_neg_list.append(test_true_neg)\n",
    "    \n",
    "xgb_random_state_df['train_accuracy'] = train_accuracy_list\n",
    "xgb_random_state_df['test_accuracy'] = test_accuracy_list\n",
    "xgb_random_state_df['train_f1_score'] = train_f1_list\n",
    "xgb_random_state_df['test_f1_score'] = test_f1_list\n",
    "xgb_random_state_df['train_true_pos'] = train_true_pos_list\n",
    "xgb_random_state_df['train_false_pos'] = train_false_pos_list\n",
    "xgb_random_state_df['train_false_neg'] = train_false_neg_list\n",
    "xgb_random_state_df['train_true_neg'] = train_true_neg_list\n",
    "xgb_random_state_df['test_true_pos'] = test_true_pos_list\n",
    "xgb_random_state_df['test_false_pos'] = test_false_pos_list\n",
    "xgb_random_state_df['test_false_neg'] = test_false_neg_list\n",
    "xgb_random_state_df['test_true_neg'] = test_true_neg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>train_true_pos</th>\n",
       "      <th>train_false_pos</th>\n",
       "      <th>train_false_neg</th>\n",
       "      <th>train_true_neg</th>\n",
       "      <th>test_true_pos</th>\n",
       "      <th>test_false_pos</th>\n",
       "      <th>test_false_neg</th>\n",
       "      <th>test_true_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997633</td>\n",
       "      <td>22974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22974</td>\n",
       "      <td>9729</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>9695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998328</td>\n",
       "      <td>22831</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22831</td>\n",
       "      <td>9872</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>9851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998109</td>\n",
       "      <td>22913</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22913</td>\n",
       "      <td>9790</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>9765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997986</td>\n",
       "      <td>23013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23013</td>\n",
       "      <td>9692</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998408</td>\n",
       "      <td>22961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22961</td>\n",
       "      <td>9745</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>9720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998428</td>\n",
       "      <td>22835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22835</td>\n",
       "      <td>9873</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>9844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998776</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>22908</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22908</td>\n",
       "      <td>9798</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>9780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998327</td>\n",
       "      <td>22834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22834</td>\n",
       "      <td>9869</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>9848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998563</td>\n",
       "      <td>22955</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22955</td>\n",
       "      <td>9751</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>9729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998350</td>\n",
       "      <td>22999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22999</td>\n",
       "      <td>9707</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>9681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id  random_state  train_accuracy  test_accuracy  train_f1_score  \\\n",
       "0       0             0             1.0       0.997637             1.0   \n",
       "1       1             1             1.0       0.998330             1.0   \n",
       "2       2             2             1.0       0.998111             1.0   \n",
       "3       3             3             1.0       0.997989             1.0   \n",
       "4       4             4             1.0       0.998410             1.0   \n",
       "5       5             5             1.0       0.998430             1.0   \n",
       "6       6             6             1.0       0.998776             1.0   \n",
       "7       7             7             1.0       0.998329             1.0   \n",
       "8       8             8             1.0       0.998565             1.0   \n",
       "9       9             9             1.0       0.998352             1.0   \n",
       "\n",
       "   test_f1_score  train_true_pos  train_false_pos  train_false_neg  \\\n",
       "0       0.997633           22974                0                0   \n",
       "1       0.998328           22831                0                0   \n",
       "2       0.998109           22913                0                0   \n",
       "3       0.997986           23013                0                0   \n",
       "4       0.998408           22961                0                0   \n",
       "5       0.998428           22835                0                0   \n",
       "6       0.998775           22908                0                0   \n",
       "7       0.998327           22834                0                0   \n",
       "8       0.998563           22955                0                0   \n",
       "9       0.998350           22999                0                0   \n",
       "\n",
       "   train_true_neg  test_true_pos  test_false_pos  test_false_neg  \\\n",
       "0           22974           9729               6              40   \n",
       "1           22831           9872               6              27   \n",
       "2           22913           9790               6              31   \n",
       "3           23013           9692               4              35   \n",
       "4           22961           9745               3              28   \n",
       "5           22835           9873               1              30   \n",
       "6           22908           9798               3              21   \n",
       "7           22834           9869               6              27   \n",
       "8           22955           9751               3              25   \n",
       "9           22999           9707               3              29   \n",
       "\n",
       "   test_true_neg  \n",
       "0           9695  \n",
       "1           9851  \n",
       "2           9765  \n",
       "3           9661  \n",
       "4           9720  \n",
       "5           9844  \n",
       "6           9780  \n",
       "7           9848  \n",
       "8           9729  \n",
       "9           9681  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_random_state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_random_state_df = pd.DataFrame(\n",
    "    {'run_id': list(range(0, 10)),\n",
    "     'random_state': list(range(0, 10))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.4278 - accuracy: 0.4243\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.4928 - accuracy: 0.5388\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.8401\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5981 - accuracy: 0.6189\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.8162\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.7818\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.6840\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.8031\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4023 - accuracy: 0.8573\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.7921\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8819\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3390 - accuracy: 0.8659\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.8018\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3799 - accuracy: 0.8440\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3831 - accuracy: 0.8734\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.8451\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8924\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3880 - accuracy: 0.8464\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3255 - accuracy: 0.8948\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8434\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8935\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8595\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8918\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.8753\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8934\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3447 - accuracy: 0.8632\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2959 - accuracy: 0.9056\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3648 - accuracy: 0.8589\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3030 - accuracy: 0.9023\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8805\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8913\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.8928\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3017 - accuracy: 0.9017\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3110 - accuracy: 0.8813\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3064 - accuracy: 0.9017\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2947 - accuracy: 0.8862\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2915 - accuracy: 0.9046\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2768 - accuracy: 0.8928\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2827 - accuracy: 0.9063\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2958 - accuracy: 0.8858\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2928 - accuracy: 0.9042\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3060 - accuracy: 0.8817\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2391 - accuracy: 0.9217\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.8792\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2707 - accuracy: 0.9114\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2801 - accuracy: 0.8925\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2651 - accuracy: 0.9116\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2947 - accuracy: 0.8867\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.9181\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2660 - accuracy: 0.9005\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2543 - accuracy: 0.9162\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2831 - accuracy: 0.8925\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2651 - accuracy: 0.9138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.0689 - accuracy: 0.5035\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.5594\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5249 - accuracy: 0.7555\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.5585\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5396 - accuracy: 0.6613\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.8182\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5758 - accuracy: 0.6205\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4199 - accuracy: 0.8806\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7484\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3761 - accuracy: 0.8968\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7100\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3740 - accuracy: 0.8900\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7003\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3840 - accuracy: 0.8745\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.8236\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3791 - accuracy: 0.8736\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3449 - accuracy: 0.8656\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.8229\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8680\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2862 - accuracy: 0.9049\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2742 - accuracy: 0.9059\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.8344\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8945\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8688\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3381 - accuracy: 0.8897\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3435 - accuracy: 0.8626\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8887\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3809 - accuracy: 0.8554\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8923\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.2354 - accuracy: 0.5145\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7607 - accuracy: 0.5403\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.7809\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.8275\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.8347\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4244 - accuracy: 0.8420\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5633 - accuracy: 0.5864\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7922\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4198 - accuracy: 0.8717\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7716\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8684\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4421 - accuracy: 0.8130\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8621\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3974 - accuracy: 0.8447\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4048 - accuracy: 0.8751\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.8124\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4139 - accuracy: 0.8651\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3818 - accuracy: 0.8502\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4125 - accuracy: 0.8568\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3197 - accuracy: 0.8820\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4158 - accuracy: 0.8650\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3748 - accuracy: 0.8527\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3697 - accuracy: 0.8828\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8578\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3627 - accuracy: 0.8847\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8670\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3972 - accuracy: 0.8587\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2891 - accuracy: 0.9095\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3700 - accuracy: 0.8572\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3739 - accuracy: 0.8823\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.8756\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.9057\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3395 - accuracy: 0.8712\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8950\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8725\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.9006\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3234 - accuracy: 0.8773\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3014 - accuracy: 0.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 10.8778 - accuracy: 0.5034\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7508 - accuracy: 0.5567\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5801 - accuracy: 0.7048\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.5387\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5409 - accuracy: 0.6685\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.8433\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.6290\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.5740\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5327 - accuracy: 0.7379\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5286 - accuracy: 0.5747\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6752 - accuracy: 0.6475\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.8375\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7387\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.8407\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7869\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.6760\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7224\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4153 - accuracy: 0.7927\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3481 - accuracy: 0.8927\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7996\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4101 - accuracy: 0.8209\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3864 - accuracy: 0.8587\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3114 - accuracy: 0.8935\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.8250\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4014 - accuracy: 0.8367\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.9043\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8863\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4036 - accuracy: 0.8336\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8940\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3876 - accuracy: 0.8432\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2638 - accuracy: 0.9124\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8916\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3490 - accuracy: 0.8600\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8993\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2955 - accuracy: 0.8867\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3188 - accuracy: 0.8976\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3250 - accuracy: 0.8727\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3212 - accuracy: 0.8919\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2560 - accuracy: 0.9138\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8916\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3029 - accuracy: 0.8917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 17.8770 - accuracy: 0.4848\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.5534\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6628 - accuracy: 0.5947\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5960 - accuracy: 0.7554\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5817 - accuracy: 0.6695\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.7321\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5611 - accuracy: 0.6765\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5284 - accuracy: 0.6901\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5268 - accuracy: 0.6567\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7823\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7063\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7087\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7642 - accuracy: 0.5908\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8815\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.8047\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7830\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5445 - accuracy: 0.6947\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.8165\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3755 - accuracy: 0.8878\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7954\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7851\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3727 - accuracy: 0.8710\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.8707\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8483\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3728 - accuracy: 0.8724\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8830\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3641 - accuracy: 0.8681\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.8986\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3746 - accuracy: 0.8689\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8773\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3183 - accuracy: 0.8867\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8566\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.8739\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2896 - accuracy: 0.9049\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3383 - accuracy: 0.8858\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2549 - accuracy: 0.9299\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3920 - accuracy: 0.8455\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.9280\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.8281\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8730\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3776 - accuracy: 0.8508\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3179 - accuracy: 0.8781\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8710\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2817 - accuracy: 0.8982\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2727 - accuracy: 0.9113\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2967 - accuracy: 0.8893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.7223 - accuracy: 0.5151\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.6714\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.7514\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8072\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5143 - accuracy: 0.6505\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7447\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7841\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4034 - accuracy: 0.8386\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.8618\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.8674\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7891\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8223\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8859\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.8415\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3938 - accuracy: 0.8766\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8704\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3730 - accuracy: 0.8816\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.8558\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3490 - accuracy: 0.8920\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8616\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8944\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3556 - accuracy: 0.8596\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.8871\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3158 - accuracy: 0.8774\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3028 - accuracy: 0.9058\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3419 - accuracy: 0.8686\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8955\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2911 - accuracy: 0.8886\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3141 - accuracy: 0.8988\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3523 - accuracy: 0.8631\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2690 - accuracy: 0.9135\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3833 - accuracy: 0.8593\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3421 - accuracy: 0.8888\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2650 - accuracy: 0.9033\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2940 - accuracy: 0.9041\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.8805\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2752 - accuracy: 0.9079\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8704\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2684 - accuracy: 0.9123\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8753\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2612 - accuracy: 0.9149\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2947 - accuracy: 0.8870\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2800 - accuracy: 0.9093\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2775 - accuracy: 0.8934\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2767 - accuracy: 0.9078\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2711 - accuracy: 0.8971\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.9221\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2828 - accuracy: 0.8915\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.9169\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2524 - accuracy: 0.9044\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2855 - accuracy: 0.9064\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2632 - accuracy: 0.8999\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.9197\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2710 - accuracy: 0.8985\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2302 - accuracy: 0.9227\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2609 - accuracy: 0.9029\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2683 - accuracy: 0.9115\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2523 - accuracy: 0.9043\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2377 - accuracy: 0.9220\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2766 - accuracy: 0.8944\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 0.9249\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2691 - accuracy: 0.8982\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.9163\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.9073\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.9273\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2884 - accuracy: 0.8932\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2261 - accuracy: 0.9258\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.9147\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2534 - accuracy: 0.9155\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2354 - accuracy: 0.9116\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.9209\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2564 - accuracy: 0.9042\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2372 - accuracy: 0.9200\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.9130\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2337 - accuracy: 0.9210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 12.9955 - accuracy: 0.4999\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5736 - accuracy: 0.7076\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8130\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6252 - accuracy: 0.6096\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5872 - accuracy: 0.5730\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6290 - accuracy: 0.5583\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6621 - accuracy: 0.6679\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.8806\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5944 - accuracy: 0.6744\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.8079\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7435 - accuracy: 0.7341\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.8052\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3756 - accuracy: 0.8692\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.8309\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4192 - accuracy: 0.8581\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3846 - accuracy: 0.8450\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.9073\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8982\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8772\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3236 - accuracy: 0.8821\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3925 - accuracy: 0.8685\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3530 - accuracy: 0.8795\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3189 - accuracy: 0.9002\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3889 - accuracy: 0.8448\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4117 - accuracy: 0.8358\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3564 - accuracy: 0.8570\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8978\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3452 - accuracy: 0.8632\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2640 - accuracy: 0.9207\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.8213\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8672\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3028 - accuracy: 0.9010\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2857 - accuracy: 0.9083\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2635 - accuracy: 0.9156\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2718 - accuracy: 0.9074\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2593 - accuracy: 0.9160\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2855 - accuracy: 0.9054\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9298\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3685 - accuracy: 0.8655\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2756 - accuracy: 0.8989\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2931 - accuracy: 0.9026\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3051 - accuracy: 0.8904\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.9146\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2333 - accuracy: 0.9260\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3728 - accuracy: 0.8656\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.8837\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2653 - accuracy: 0.9040\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2837 - accuracy: 0.9053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 12.0974 - accuracy: 0.4989\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5301\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.8080\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.7540\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.7562\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.8337\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5113 - accuracy: 0.7157\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4388 - accuracy: 0.8688\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4320 - accuracy: 0.8278\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4083 - accuracy: 0.8796\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7272\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8817\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3946 - accuracy: 0.8406\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3731 - accuracy: 0.8896\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4119 - accuracy: 0.8362\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3725 - accuracy: 0.8859\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3750 - accuracy: 0.8534\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8907\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3888 - accuracy: 0.8475\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.8895\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3615 - accuracy: 0.8589\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.8827\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8737\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3115 - accuracy: 0.9044\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3721 - accuracy: 0.8584\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8929\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8730\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3483 - accuracy: 0.8874\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8674\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3174 - accuracy: 0.8995\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8693\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8925\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2994 - accuracy: 0.8852\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3187 - accuracy: 0.8979\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3145 - accuracy: 0.8789\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.8959\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2772 - accuracy: 0.8944\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3091 - accuracy: 0.8995\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8706\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2960 - accuracy: 0.9034\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3062 - accuracy: 0.8855\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2693 - accuracy: 0.9135\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8740\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2770 - accuracy: 0.9094\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3034 - accuracy: 0.8846\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2839 - accuracy: 0.9075\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3034 - accuracy: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.2079 - accuracy: 0.5043\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6007 - accuracy: 0.5913\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4244 - accuracy: 0.8287\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7873\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.8130\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.8104\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.8140\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3940 - accuracy: 0.8764\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4059 - accuracy: 0.8336\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3869 - accuracy: 0.8773\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.8331\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3710 - accuracy: 0.8820\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8531\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3522 - accuracy: 0.8866\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3716 - accuracy: 0.8550\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3641 - accuracy: 0.8826\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3710 - accuracy: 0.8522\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3222 - accuracy: 0.8997\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8466\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3178 - accuracy: 0.9009\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8667\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.9088\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3400 - accuracy: 0.8690\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3207 - accuracy: 0.8950\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3116 - accuracy: 0.8828\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2881 - accuracy: 0.9089\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8647\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3122 - accuracy: 0.8998\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3207 - accuracy: 0.8742\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3129 - accuracy: 0.8972\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3213 - accuracy: 0.8742\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2703 - accuracy: 0.9164\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8704\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2640 - accuracy: 0.9175\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3156 - accuracy: 0.8813\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3061 - accuracy: 0.9001\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2774 - accuracy: 0.8944\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2930 - accuracy: 0.9036\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8733\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2668 - accuracy: 0.9147\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8747\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2892 - accuracy: 0.9046\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2774 - accuracy: 0.8941\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2684 - accuracy: 0.9138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.4062 - accuracy: 0.5023\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5868 - accuracy: 0.6457\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.8204\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.8479\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5479 - accuracy: 0.6596\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4054 - accuracy: 0.8840\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3664 - accuracy: 0.8689\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.6945\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5281 - accuracy: 0.7769\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3395 - accuracy: 0.8830\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.8031\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3757 - accuracy: 0.8767\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3761 - accuracy: 0.8576\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3848 - accuracy: 0.8753\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3999 - accuracy: 0.8401\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3876 - accuracy: 0.8765\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2796 - accuracy: 0.9118\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4069 - accuracy: 0.8224\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2969 - accuracy: 0.9045\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8478\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3125 - accuracy: 0.9017\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3793 - accuracy: 0.8510\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8924\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8739\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3124 - accuracy: 0.8889\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3113 - accuracy: 0.8948\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2739 - accuracy: 0.9116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n",
      "/home/ml/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning:\n",
      "\n",
      "`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "train_f1_list = []\n",
    "test_f1_list = []\n",
    "train_true_pos_list = []\n",
    "train_false_pos_list = []\n",
    "train_false_neg_list = []\n",
    "train_true_neg_list = []\n",
    "test_true_pos_list = []\n",
    "test_false_pos_list = []\n",
    "test_false_neg_list = []\n",
    "test_true_neg_list = []\n",
    "\n",
    "\n",
    "for j in range(10):\n",
    "    \n",
    "    shufled_agersens_df = full_upd_agersens_df.sample(frac=1, random_state=j).reset_index(drop=True)\n",
    "    \n",
    "    X = shufled_agersens_df.drop(columns=['target'])\n",
    "    y = shufled_agersens_df['target']\n",
    "\n",
    "    #split data into test and training sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=j)\n",
    "\n",
    "    #training part\n",
    "    #combine them back for resampling\n",
    "    train_data = pd.concat([X_train, y_train], axis=1)\n",
    "    \n",
    "    # separate minority and majority classes\n",
    "    negative = train_data[train_data['target']==1]\n",
    "    positive = train_data[train_data['target']==0]\n",
    "\n",
    "    # downsample majority\n",
    "    neg_downsampled = resample(negative,\n",
    "     replace=True, # sample with replacement\n",
    "     n_samples=len(positive), # match number in minority class\n",
    "     random_state=j) # reproducible results\n",
    "    # combine minority and downsampled majority\n",
    "    train_downsampled = pd.concat([positive, neg_downsampled])\n",
    "\n",
    "    #testing part\n",
    "    #combine them back for resampling\n",
    "    test_data = pd.concat([X_test, y_test], axis=1)\n",
    "    \n",
    "    # separate minority and majority classes\n",
    "    negative = test_data[test_data['target']==1]\n",
    "    positive = test_data[test_data['target']==0]\n",
    "\n",
    "    # downsample majority\n",
    "    neg_downsampled = resample(negative,\n",
    "     replace=True, # sample with replacement\n",
    "     n_samples=len(positive), # match number in minority class\n",
    "     random_state=j) # reproducible results\n",
    "    # combine minority and downsampled majority\n",
    "    test_downsampled = pd.concat([positive, neg_downsampled])\n",
    "\n",
    "\n",
    "    X_train = train_downsampled.drop(['target'],axis=1)\n",
    "\n",
    "    X_test =  test_downsampled.drop(['target'],axis=1)\n",
    "\n",
    "    y_train = train_downsampled['target']\n",
    "\n",
    "    y_test = test_downsampled['target']\n",
    "    \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "    nn_model = Sequential()\n",
    "    nn_model.add(Dense(128, activation='relu', input_shape=(len(X_train.columns),)))\n",
    "    nn_model.add(Dense(64, activation='relu'))\n",
    "    nn_model.add(Dense(32, activation='relu'))\n",
    "    nn_model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    nn_model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    nn_model.fit(X_train, y_train, epochs=100, batch_size=10000, callbacks=[callback], verbose=1)\n",
    "    \n",
    "    # Predict the model\n",
    "    nn_train_preds = nn_model.predict_classes(X_train)\n",
    "    nn_test_preds = nn_model.predict_classes(X_test)\n",
    "\n",
    "    train_acc_nn = accuracy_score(y_train, nn_train_preds)\n",
    "    test_acc_nn = accuracy_score(y_test, nn_test_preds)\n",
    "    \n",
    "    train_f1_nn = f1_score(y_train, nn_train_preds)\n",
    "    test_f1_nn = f1_score(y_test, nn_test_preds)\n",
    "\n",
    "    train_conf_matrix_nn = confusion_matrix(y_train, nn_train_preds)\n",
    "    train_true_pos = train_conf_matrix_nn[0][0]\n",
    "    train_false_pos = train_conf_matrix_nn[0][1]\n",
    "    train_false_neg = train_conf_matrix_nn[1][0]\n",
    "    train_true_neg = train_conf_matrix_nn[1][1]\n",
    "    \n",
    "    test_conf_matrix_nn = confusion_matrix(y_test, nn_test_preds)\n",
    "    test_true_pos = test_conf_matrix_nn[0][0]\n",
    "    test_false_pos = test_conf_matrix_nn[0][1]\n",
    "    test_false_neg = test_conf_matrix_nn[1][0]\n",
    "    test_true_neg = test_conf_matrix_nn[1][1]   \n",
    "    \n",
    "    train_accuracy_list.append(train_acc_nn)\n",
    "    test_accuracy_list.append(test_acc_nn)\n",
    "    \n",
    "    train_f1_list.append(train_f1_nn)\n",
    "    test_f1_list.append(test_f1_nn)\n",
    "    \n",
    "    train_true_pos_list.append(train_true_pos)\n",
    "    train_false_pos_list.append(train_false_pos)    \n",
    "    train_false_neg_list.append(train_false_neg)\n",
    "    train_true_neg_list.append(train_true_neg)\n",
    "    \n",
    "    test_true_pos_list.append(test_true_pos)\n",
    "    test_false_pos_list.append(test_false_pos)    \n",
    "    test_false_neg_list.append(test_false_neg)\n",
    "    test_true_neg_list.append(test_true_neg)\n",
    "    \n",
    "nn_random_state_df['train_accuracy'] = train_accuracy_list\n",
    "nn_random_state_df['test_accuracy'] = test_accuracy_list\n",
    "nn_random_state_df['train_f1_score'] = train_f1_list\n",
    "nn_random_state_df['test_f1_score'] = test_f1_list\n",
    "nn_random_state_df['train_true_pos'] = train_true_pos_list\n",
    "nn_random_state_df['train_false_pos'] = train_false_pos_list\n",
    "nn_random_state_df['train_false_neg'] = train_false_neg_list\n",
    "nn_random_state_df['train_true_neg'] = train_true_neg_list\n",
    "nn_random_state_df['test_true_pos'] = test_true_pos_list\n",
    "nn_random_state_df['test_false_pos'] = test_false_pos_list\n",
    "nn_random_state_df['test_false_neg'] = test_false_neg_list\n",
    "nn_random_state_df['test_true_neg'] = test_true_neg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>random_state</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>train_true_pos</th>\n",
       "      <th>train_false_pos</th>\n",
       "      <th>train_false_neg</th>\n",
       "      <th>train_true_neg</th>\n",
       "      <th>test_true_pos</th>\n",
       "      <th>test_false_pos</th>\n",
       "      <th>test_false_neg</th>\n",
       "      <th>test_true_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882715</td>\n",
       "      <td>0.880996</td>\n",
       "      <td>0.892988</td>\n",
       "      <td>0.891815</td>\n",
       "      <td>18074</td>\n",
       "      <td>4900</td>\n",
       "      <td>489</td>\n",
       "      <td>22485</td>\n",
       "      <td>7603</td>\n",
       "      <td>2132</td>\n",
       "      <td>185</td>\n",
       "      <td>9550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.937191</td>\n",
       "      <td>0.937740</td>\n",
       "      <td>0.936071</td>\n",
       "      <td>0.936663</td>\n",
       "      <td>21797</td>\n",
       "      <td>1034</td>\n",
       "      <td>1834</td>\n",
       "      <td>20997</td>\n",
       "      <td>9431</td>\n",
       "      <td>447</td>\n",
       "      <td>783</td>\n",
       "      <td>9095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.862305</td>\n",
       "      <td>0.864996</td>\n",
       "      <td>0.877127</td>\n",
       "      <td>0.879416</td>\n",
       "      <td>16994</td>\n",
       "      <td>5919</td>\n",
       "      <td>391</td>\n",
       "      <td>22522</td>\n",
       "      <td>7302</td>\n",
       "      <td>2494</td>\n",
       "      <td>151</td>\n",
       "      <td>9645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.935363</td>\n",
       "      <td>0.937345</td>\n",
       "      <td>0.933837</td>\n",
       "      <td>0.935989</td>\n",
       "      <td>22056</td>\n",
       "      <td>957</td>\n",
       "      <td>2018</td>\n",
       "      <td>20995</td>\n",
       "      <td>9294</td>\n",
       "      <td>402</td>\n",
       "      <td>813</td>\n",
       "      <td>8883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.919102</td>\n",
       "      <td>0.919009</td>\n",
       "      <td>0.922847</td>\n",
       "      <td>0.922874</td>\n",
       "      <td>19989</td>\n",
       "      <td>2972</td>\n",
       "      <td>743</td>\n",
       "      <td>22218</td>\n",
       "      <td>8470</td>\n",
       "      <td>1278</td>\n",
       "      <td>301</td>\n",
       "      <td>9447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.888877</td>\n",
       "      <td>0.890267</td>\n",
       "      <td>0.898131</td>\n",
       "      <td>0.899308</td>\n",
       "      <td>18223</td>\n",
       "      <td>4612</td>\n",
       "      <td>463</td>\n",
       "      <td>22372</td>\n",
       "      <td>7904</td>\n",
       "      <td>1970</td>\n",
       "      <td>197</td>\n",
       "      <td>9677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.879278</td>\n",
       "      <td>0.879604</td>\n",
       "      <td>0.890304</td>\n",
       "      <td>0.890639</td>\n",
       "      <td>17840</td>\n",
       "      <td>5068</td>\n",
       "      <td>463</td>\n",
       "      <td>22445</td>\n",
       "      <td>7632</td>\n",
       "      <td>2169</td>\n",
       "      <td>191</td>\n",
       "      <td>9610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.931440</td>\n",
       "      <td>0.933114</td>\n",
       "      <td>0.928917</td>\n",
       "      <td>0.930899</td>\n",
       "      <td>22079</td>\n",
       "      <td>755</td>\n",
       "      <td>2376</td>\n",
       "      <td>20458</td>\n",
       "      <td>9531</td>\n",
       "      <td>344</td>\n",
       "      <td>977</td>\n",
       "      <td>8898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.872816</td>\n",
       "      <td>0.872668</td>\n",
       "      <td>0.885395</td>\n",
       "      <td>0.885340</td>\n",
       "      <td>17516</td>\n",
       "      <td>5439</td>\n",
       "      <td>400</td>\n",
       "      <td>22555</td>\n",
       "      <td>7434</td>\n",
       "      <td>2320</td>\n",
       "      <td>164</td>\n",
       "      <td>9590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.885778</td>\n",
       "      <td>0.889238</td>\n",
       "      <td>0.895700</td>\n",
       "      <td>0.898475</td>\n",
       "      <td>18184</td>\n",
       "      <td>4815</td>\n",
       "      <td>439</td>\n",
       "      <td>22560</td>\n",
       "      <td>7751</td>\n",
       "      <td>1959</td>\n",
       "      <td>192</td>\n",
       "      <td>9518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id  random_state  train_accuracy  test_accuracy  train_f1_score  \\\n",
       "0       0             0        0.882715       0.880996        0.892988   \n",
       "1       1             1        0.937191       0.937740        0.936071   \n",
       "2       2             2        0.862305       0.864996        0.877127   \n",
       "3       3             3        0.935363       0.937345        0.933837   \n",
       "4       4             4        0.919102       0.919009        0.922847   \n",
       "5       5             5        0.888877       0.890267        0.898131   \n",
       "6       6             6        0.879278       0.879604        0.890304   \n",
       "7       7             7        0.931440       0.933114        0.928917   \n",
       "8       8             8        0.872816       0.872668        0.885395   \n",
       "9       9             9        0.885778       0.889238        0.895700   \n",
       "\n",
       "   test_f1_score  train_true_pos  train_false_pos  train_false_neg  \\\n",
       "0       0.891815           18074             4900              489   \n",
       "1       0.936663           21797             1034             1834   \n",
       "2       0.879416           16994             5919              391   \n",
       "3       0.935989           22056              957             2018   \n",
       "4       0.922874           19989             2972              743   \n",
       "5       0.899308           18223             4612              463   \n",
       "6       0.890639           17840             5068              463   \n",
       "7       0.930899           22079              755             2376   \n",
       "8       0.885340           17516             5439              400   \n",
       "9       0.898475           18184             4815              439   \n",
       "\n",
       "   train_true_neg  test_true_pos  test_false_pos  test_false_neg  \\\n",
       "0           22485           7603            2132             185   \n",
       "1           20997           9431             447             783   \n",
       "2           22522           7302            2494             151   \n",
       "3           20995           9294             402             813   \n",
       "4           22218           8470            1278             301   \n",
       "5           22372           7904            1970             197   \n",
       "6           22445           7632            2169             191   \n",
       "7           20458           9531             344             977   \n",
       "8           22555           7434            2320             164   \n",
       "9           22560           7751            1959             192   \n",
       "\n",
       "   test_true_neg  \n",
       "0           9550  \n",
       "1           9095  \n",
       "2           9645  \n",
       "3           8883  \n",
       "4           9447  \n",
       "5           9677  \n",
       "6           9610  \n",
       "7           8898  \n",
       "8           9590  \n",
       "9           9518  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_random_state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above experiments, I can infer that `XGBoost Classifier` performs the best out of all the models with `Random Forest Classifier` coming in a close second. I think `SVM` and `Neural Networks` does a decent enough job in classifying the data. \n",
    "\n",
    "Downsampling the data really did help in the prediction of `Non-Spurious` data. The `Neural Networks` performed better, I was able to run `SVM` with less data. Both `XGBoost Classifier`and `Random Forest Classifier` does a much better job and there is also a huge reduction in the values for False Positives and False Negatives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
